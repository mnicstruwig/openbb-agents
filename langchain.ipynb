{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd2896b8-d727-4d62-aed4-664f084d0cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "chat_model = ChatOpenAI(model=\"gpt-4-1106-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b586a1b2-2bea-40df-a934-543beb4166de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nGlee Socks.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "llm.invoke(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83256079-0377-47a4-8600-d8ccde6a3cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Choosing a company name for a business that specializes in colorful socks can be quite fun. You'll want a name that is catchy, memorable, and reflects the vibrant and playful nature of your product. Here are some suggestions:\\n\\n1. Sock Spectrum\\n2. VividFeet\\n3. HueHosiery\\n4. ColorPopSocks\\n5. RainbowToes\\n6. PizzazzSocks\\n7. BrightSteps\\n8. KaleidoSox\\n9. PrismPeds\\n10. ArtiSox\\n11. DazzleHeels\\n12. Socktastic Colors\\n13. FootFiesta\\n14. ZingSocks\\n15. HappyHeel Threads\\n\\nRemember to check for domain availability if you plan to sell online, and ensure the name isn't already trademarked or in heavy use by another company in your market. It's always a good idea to test your favorite names with potential customers to see which one resonates the most.\")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4ce6b51-2b40-499d-a44e-2b50cfe40d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good name for a company that makes colorful socks?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "prompt.format(product=\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9f8bcde-e60c-4cf6-86ed-d1f8d8530a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1de64be0-d13d-4dee-9bbf-87a41a74a81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant that translates english to afrikaans.'),\n",
       " HumanMessage(content='Hello there, you fool.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "msgs = chat_prompt.format_messages(\n",
    "    input_language=\"english\",\n",
    "    output_language=\"afrikaans\",\n",
    "    text=\"Hello there, you fool.\"\n",
    ")\n",
    "\n",
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "077feeb0-01b0-4512-a003-2bda3ae513c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hallo daar, jy dwaas.')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "543b1a7c-f9ae-400f-89da-2f6353ae8b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hy', 'bye']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "       return text.strip().split(\", \")     \n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hy, bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f927f35a-b2af-4946-8b19-bff48c2c8788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red', 'blue', 'green', 'yellow', 'purple']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser[List[str]]):\n",
    "\n",
    "    def parse(self, text:str) -> List[str]:\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = chat_prompt | ChatOpenAI() | CommaSeparatedListOutputParser()\n",
    "chain.invoke({\"text\": \"colors\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6aae6b6e-54a9-4b78-8049-b34873f3faa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['text'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='\\nYou are a helpful assistant who generates comma separated lists.\\nA user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\\nONLY return a comma separated list, and nothing more.\\n')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "794f34da-3e2d-4077-b3d6-67f4a669f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CustomPrompt\n",
    "import inspect\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from pydantic.v1 import BaseModel, validator\n",
    "\n",
    "PROMPT = \"\"\"\\\n",
    "Given the function name and source code, generate an simplified English language explanation of the function.\n",
    "Function Name: {function_name}\n",
    "Source Code:\n",
    "{source_code}\n",
    "Explanation:\n",
    "\"\"\"\n",
    "\n",
    "class FunctionExplainerPromptTemplate(StringPromptTemplate, BaseModel):\n",
    "    \"\"\"Custom prompt template\"\"\"\n",
    "\n",
    "    @validator(\"input_variables\")\n",
    "    def validate_input_variables(cls, v):  # Note: This is awesome -- it's a pre-flight error check\n",
    "        \"\"\"Validate that the input variables are correct.\"\"\"\n",
    "        if len(v) != 1 or \"function_name\" not in v:\n",
    "            raise ValueError(\"function_name must be the only input variable.\")\n",
    "        return v\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        source_code = inspect.getsource(kwargs[\"function_name\"])\n",
    "\n",
    "        prompt = PROMPT.format(\n",
    "            function_name=kwargs[\"function_name\"].__name__,\n",
    "            source_code=source_code\n",
    "        )\n",
    "        return prompt\n",
    "\n",
    "    def _prompt_type(self):\n",
    "        return \"function-explainer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b8957474-ae04-4874-8557-e12a1665a628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The function \"signature\" takes in an object and returns a signature object for that object. It has the option to follow wrapped objects, use specific global and local variables, and evaluate strings. The function is implemented by calling the \"Signature.from_callable\" function with the given parameters.')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_explainer = FunctionExplainerPromptTemplate(\n",
    "    input_variables=[\"function_name\"]\n",
    ")\n",
    "\n",
    "fn_explainer.format(function_name=inspect.signature)\n",
    "\n",
    "chain = fn_explainer | ChatOpenAI()\n",
    "chain.invoke({\"function_name\": inspect.signature})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ed95fec0-86cc-4f6f-ba76-44c80442c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's figure out how to do output parsing\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "class Joke(BaseModel):  # The output model\n",
    "    setup: str = Field(description=\"question to setup the joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(  # The prompt fed into as input\n",
    "    template=\"Answer the query.\\n{format_instructions}\\n{query}\\n\",  # This is the prompt template\n",
    "    input_variables=[\"query\"],  # These are the only inputs we need to provide.\n",
    "    partial_variables={\n",
    "        \"format_instructions\": parser.get_format_instructions()  # We specify particular format instructions that get put into the template\n",
    "    }\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "output = chain.invoke({\"query\": \"Tell me a joke.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "46554b3f-51dc-428a-b699-e80778b4758e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything!')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6823f9-fe11-44cc-8801-be40cb54b007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
